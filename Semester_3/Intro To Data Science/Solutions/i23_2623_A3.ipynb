{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1 (SMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:36:10.818332Z",
     "start_time": "2024-10-27T11:36:10.812765Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag Conversion Function:\n",
    "\n",
    "    Used to convert NLTK Part of Speech Tags to WordNet Part of Speech Tags. Used for lemmatization where correct POS tag helps in reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:36:10.840134Z",
     "start_time": "2024-10-27T11:36:10.833389Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to convert NLTK POS tags to WordNet POS tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Reading/Data Frame Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:36:11.209553Z",
     "start_time": "2024-10-27T11:36:11.162467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_filename = \"SMSSpamCollection\"\n",
    "sms = pd.read_csv(sms_filename, sep='\\t', header=None, names=['label', 'message'])\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization Step:\n",
    "\n",
    "    1. Converting all messages to lowercase to establish consistency across messages\n",
    "    2. Removing all leading whitespaces\n",
    "    3. Removing all punctuation and numbers to reduce noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:36:11.614780Z",
     "start_time": "2024-10-27T11:36:11.538725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in  a wkly comp to win fa cup final...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  go until jurong point crazy available only in ...\n",
       "1   ham                            ok lar joking wif u oni\n",
       "2  spam  free entry in  a wkly comp to win fa cup final...\n",
       "3   ham        u dun say so early hor u c already then say\n",
       "4   ham  nah i dont think he goes to usf he lives aroun..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms['message'] = sms['message'].str.lower()\n",
    "\n",
    "sms['message'] = sms['message'].str.strip()\n",
    "\n",
    "sms['message'] = sms['message'].str.replace(r'[^\\w\\s]', '', regex=True) #remove punctuation\n",
    "sms['message'] = sms['message'].str.replace(r'\\d+', '', regex=True) #remove numbers\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopword removal to avoid unncessary computations later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:36:35.149593Z",
     "start_time": "2024-10-27T11:36:11.711031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah dont think goes usf lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  go jurong point crazy available bugis n great ...\n",
       "1   ham                            ok lar joking wif u oni\n",
       "2  spam  free entry wkly comp win fa cup final tkts st ...\n",
       "3   ham                u dun say early hor u c already say\n",
       "4   ham        nah dont think goes usf lives around though"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms['message'] = sms['message'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords.words('english'))]))\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization step to facilitate advanced text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:36:35.988664Z",
     "start_time": "2024-10-27T11:36:35.246901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah dont think goes usf lives around though</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  \\\n",
       "0   ham  go jurong point crazy available bugis n great ...   \n",
       "1   ham                            ok lar joking wif u oni   \n",
       "2  spam  free entry wkly comp win fa cup final tkts st ...   \n",
       "3   ham                u dun say early hor u c already say   \n",
       "4   ham        nah dont think goes usf lives around though   \n",
       "\n",
       "                                              tokens  \n",
       "0  [go, jurong, point, crazy, available, bugis, n...  \n",
       "1                     [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, wkly, comp, win, fa, cup, final,...  \n",
       "3      [u, dun, say, early, hor, u, c, already, say]  \n",
       "4  [nah, dont, think, goes, usf, lives, around, t...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms['tokens'] = sms['message'].apply(word_tokenize)\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming And Lemmatization to reduce words to their dictionary form so that text is standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:36:44.159276Z",
     "start_time": "2024-10-27T11:36:36.098136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>tokens</th>\n",
       "      <th>processed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "      <td>[free, entri, wkli, comp, win, fa, cup, final,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah dont think goes usf lives around though</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  \\\n",
       "0   ham  go jurong point crazy available bugis n great ...   \n",
       "1   ham                            ok lar joking wif u oni   \n",
       "2  spam  free entry wkly comp win fa cup final tkts st ...   \n",
       "3   ham                u dun say early hor u c already say   \n",
       "4   ham        nah dont think goes usf lives around though   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                     [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, wkly, comp, win, fa, cup, final,...   \n",
       "3      [u, dun, say, early, hor, u, c, already, say]   \n",
       "4  [nah, dont, think, goes, usf, lives, around, t...   \n",
       "\n",
       "                                    processed_tokens  \n",
       "0  [go, jurong, point, crazi, avail, bugi, n, gre...  \n",
       "1                       [ok, lar, joke, wif, u, oni]  \n",
       "2  [free, entri, wkli, comp, win, fa, cup, final,...  \n",
       "3      [u, dun, say, earli, hor, u, c, alreadi, say]  \n",
       "4  [nah, dont, think, go, usf, life, around, though]  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lemmatize the tokens with POS tagging\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "#Apply Lemmatization and Stemming\n",
    "def process_tokens(tokens):\n",
    "    #POS Tagging\n",
    "    pos_tagged_tokens = pos_tag(tokens)  # Tag each token with its POS\n",
    "    \n",
    "    #Lemmatization with PartOfSpeech tagging\n",
    "    lemmatized_tokens = [\n",
    "        lemmatizer.lemmatize(token, get_wordnet_pos(pos)) for token, pos in pos_tagged_tokens\n",
    "    ]\n",
    "    \n",
    "    #Stemming\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in lemmatized_tokens]\n",
    "    \n",
    "    return stemmed_tokens\n",
    "\n",
    "sms['processed_tokens'] = sms['tokens'].apply(process_tokens)\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N-Gram Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate n-grams for a specific number n which helps identify context in phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:36:44.253944Z",
     "start_time": "2024-10-27T11:36:44.250375Z"
    }
   },
   "outputs": [],
   "source": [
    "def ngram_generator(tokens, n):\n",
    "    return list(ngrams(tokens, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate N-Grams (N = 1 to 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:36:44.608531Z",
     "start_time": "2024-10-27T11:36:44.338924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>tokens</th>\n",
       "      <th>processed_tokens</th>\n",
       "      <th>ngrams_1</th>\n",
       "      <th>ngrams_2</th>\n",
       "      <th>ngrams_3</th>\n",
       "      <th>ngrams_4</th>\n",
       "      <th>ngrams_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>[(go,), (jurong,), (point,), (crazi,), (avail,...</td>\n",
       "      <td>[(go, jurong), (jurong, point), (point, crazi)...</td>\n",
       "      <td>[(go, jurong, point), (jurong, point, crazi), ...</td>\n",
       "      <td>[(go, jurong, point, crazi), (jurong, point, c...</td>\n",
       "      <td>[(go, jurong, point, crazi, avail), (jurong, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>[(ok,), (lar,), (joke,), (wif,), (u,), (oni,)]</td>\n",
       "      <td>[(ok, lar), (lar, joke), (joke, wif), (wif, u)...</td>\n",
       "      <td>[(ok, lar, joke), (lar, joke, wif), (joke, wif...</td>\n",
       "      <td>[(ok, lar, joke, wif), (lar, joke, wif, u), (j...</td>\n",
       "      <td>[(ok, lar, joke, wif, u), (lar, joke, wif, u, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "      <td>[free, entri, wkli, comp, win, fa, cup, final,...</td>\n",
       "      <td>[(free,), (entri,), (wkli,), (comp,), (win,), ...</td>\n",
       "      <td>[(free, entri), (entri, wkli), (wkli, comp), (...</td>\n",
       "      <td>[(free, entri, wkli), (entri, wkli, comp), (wk...</td>\n",
       "      <td>[(free, entri, wkli, comp), (entri, wkli, comp...</td>\n",
       "      <td>[(free, entri, wkli, comp, win), (entri, wkli,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>[(u,), (dun,), (say,), (earli,), (hor,), (u,),...</td>\n",
       "      <td>[(u, dun), (dun, say), (say, earli), (earli, h...</td>\n",
       "      <td>[(u, dun, say), (dun, say, earli), (say, earli...</td>\n",
       "      <td>[(u, dun, say, earli), (dun, say, earli, hor),...</td>\n",
       "      <td>[(u, dun, say, earli, hor), (dun, say, earli, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah dont think goes usf lives around though</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
       "      <td>[(nah,), (dont,), (think,), (go,), (usf,), (li...</td>\n",
       "      <td>[(nah, dont), (dont, think), (think, go), (go,...</td>\n",
       "      <td>[(nah, dont, think), (dont, think, go), (think...</td>\n",
       "      <td>[(nah, dont, think, go), (dont, think, go, usf...</td>\n",
       "      <td>[(nah, dont, think, go, usf), (dont, think, go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  \\\n",
       "0   ham  go jurong point crazy available bugis n great ...   \n",
       "1   ham                            ok lar joking wif u oni   \n",
       "2  spam  free entry wkly comp win fa cup final tkts st ...   \n",
       "3   ham                u dun say early hor u c already say   \n",
       "4   ham        nah dont think goes usf lives around though   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                     [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, wkly, comp, win, fa, cup, final,...   \n",
       "3      [u, dun, say, early, hor, u, c, already, say]   \n",
       "4  [nah, dont, think, goes, usf, lives, around, t...   \n",
       "\n",
       "                                    processed_tokens  \\\n",
       "0  [go, jurong, point, crazi, avail, bugi, n, gre...   \n",
       "1                       [ok, lar, joke, wif, u, oni]   \n",
       "2  [free, entri, wkli, comp, win, fa, cup, final,...   \n",
       "3      [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "4  [nah, dont, think, go, usf, life, around, though]   \n",
       "\n",
       "                                            ngrams_1  \\\n",
       "0  [(go,), (jurong,), (point,), (crazi,), (avail,...   \n",
       "1     [(ok,), (lar,), (joke,), (wif,), (u,), (oni,)]   \n",
       "2  [(free,), (entri,), (wkli,), (comp,), (win,), ...   \n",
       "3  [(u,), (dun,), (say,), (earli,), (hor,), (u,),...   \n",
       "4  [(nah,), (dont,), (think,), (go,), (usf,), (li...   \n",
       "\n",
       "                                            ngrams_2  \\\n",
       "0  [(go, jurong), (jurong, point), (point, crazi)...   \n",
       "1  [(ok, lar), (lar, joke), (joke, wif), (wif, u)...   \n",
       "2  [(free, entri), (entri, wkli), (wkli, comp), (...   \n",
       "3  [(u, dun), (dun, say), (say, earli), (earli, h...   \n",
       "4  [(nah, dont), (dont, think), (think, go), (go,...   \n",
       "\n",
       "                                            ngrams_3  \\\n",
       "0  [(go, jurong, point), (jurong, point, crazi), ...   \n",
       "1  [(ok, lar, joke), (lar, joke, wif), (joke, wif...   \n",
       "2  [(free, entri, wkli), (entri, wkli, comp), (wk...   \n",
       "3  [(u, dun, say), (dun, say, earli), (say, earli...   \n",
       "4  [(nah, dont, think), (dont, think, go), (think...   \n",
       "\n",
       "                                            ngrams_4  \\\n",
       "0  [(go, jurong, point, crazi), (jurong, point, c...   \n",
       "1  [(ok, lar, joke, wif), (lar, joke, wif, u), (j...   \n",
       "2  [(free, entri, wkli, comp), (entri, wkli, comp...   \n",
       "3  [(u, dun, say, earli), (dun, say, earli, hor),...   \n",
       "4  [(nah, dont, think, go), (dont, think, go, usf...   \n",
       "\n",
       "                                            ngrams_5  \n",
       "0  [(go, jurong, point, crazi, avail), (jurong, p...  \n",
       "1  [(ok, lar, joke, wif, u), (lar, joke, wif, u, ...  \n",
       "2  [(free, entri, wkli, comp, win), (entri, wkli,...  \n",
       "3  [(u, dun, say, earli, hor), (dun, say, earli, ...  \n",
       "4  [(nah, dont, think, go, usf), (dont, think, go...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    column_name = f'ngrams_{i}'\n",
    "    sms[column_name] = sms['processed_tokens'].apply(lambda x: ngram_generator(x, i))\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:36:44.780245Z",
     "start_time": "2024-10-27T11:36:44.702418Z"
    }
   },
   "outputs": [],
   "source": [
    "#count spam messages n-grams occurrences\n",
    "spam_ngram_count = {}\n",
    "spam_sms = sms[sms['label'] == 'spam']\n",
    "for i in range(1, 6):\n",
    "    spam_ngram_count[i] = Counter([ngram for ngrams_list in spam_sms[f'ngrams_{i}'] for ngram in ngrams_list])\n",
    "\n",
    "#count human messages n-grams occurrences\n",
    "ham_ngram_count = {}\n",
    "ham_sms = sms[sms['label'] == 'ham']\n",
    "for i in range(1, 6):\n",
    "    ham_ngram_count[i] = Counter([ngram for ngrams_list in ham_sms[f'ngrams_{i}'] for ngram in ngrams_list])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Common Phrases in Spam Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:36:44.932719Z",
     "start_time": "2024-10-27T11:36:44.921806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 1-grams: [(('call',), 369), (('free',), 219), (('txt',), 163), (('u',), 163), (('ur',), 144), (('text',), 139), (('mobil',), 136), (('stop',), 118), (('claim',), 115), (('repli',), 110)]\n",
      "\n",
      "Top 10 2-grams: [(('pleas', 'call'), 46), (('po', 'box'), 31), (('tri', 'contact'), 28), (('custom', 'servic'), 27), (('p', 'per'), 25), (('contact', 'u'), 24), (('guarante', 'call'), 23), (('call', 'landlin'), 23), (('prize', 'guarante'), 22), (('await', 'collect'), 22)]\n",
      "\n",
      "Top 10 3-grams: [(('prize', 'guarante', 'call'), 21), (('call', 'land', 'line'), 18), (('call', 'custom', 'servic'), 16), (('privat', 'account', 'statement'), 16), (('tri', 'contact', 'u'), 16), (('call', 'identifi', 'code'), 15), (('guarante', 'call', 'land'), 15), (('call', 'p', 'per'), 15), (('identifi', 'code', 'expir'), 14), (('land', 'line', 'claim'), 14)]\n",
      "\n",
      "Top 10 4-grams: [(('prize', 'guarante', 'call', 'land'), 15), (('guarante', 'call', 'land', 'line'), 15), (('call', 'identifi', 'code', 'expir'), 14), (('call', 'land', 'line', 'claim'), 14), (('draw', 'show', 'prize', 'guarante'), 13), (('show', 'prize', 'guarante', 'call'), 13), (('privat', 'account', 'statement', 'show'), 13), (('account', 'statement', 'show', 'unredeem'), 13), (('pleas', 'call', 'custom', 'servic'), 11), (('point', 'call', 'identifi', 'code'), 11)]\n",
      "\n",
      "Top 10 5-grams: [(('prize', 'guarante', 'call', 'land', 'line'), 15), (('guarante', 'call', 'land', 'line', 'claim'), 14), (('draw', 'show', 'prize', 'guarante', 'call'), 13), (('privat', 'account', 'statement', 'show', 'unredeem'), 13), (('point', 'call', 'identifi', 'code', 'expir'), 11), (('call', 'land', 'line', 'claim', 'valid'), 9), (('land', 'line', 'claim', 'valid', 'hr'), 9), (('show', 'unredeem', 'point', 'call', 'identifi'), 9), (('unredeem', 'point', 'call', 'identifi', 'code'), 9), (('tri', 'contact', 'u', 'today', 'draw'), 9)]\n"
     ]
    }
   ],
   "source": [
    "#display the 10 most common n-grams for each level from 1 to 5\n",
    "for i in range(1, 6):\n",
    "    top_ngrams = spam_ngram_count[i].most_common(10)\n",
    "    print(f\"\\nTop 10 {i}-grams:\", top_ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Common Phrases in Organic Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T11:36:45.673737Z",
     "start_time": "2024-10-27T11:36:45.631161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 1-grams: [(('u',), 1056), (('get',), 609), (('go',), 521), (('im',), 464), (('come',), 321), (('call',), 289), (('dont',), 276), (('ltgt',), 276), (('ok',), 273), (('know',), 256)]\n",
      "\n",
      "Top 10 2-grams: [(('gon', 'na'), 58), (('call', 'later'), 52), (('ill', 'call'), 48), (('let', 'know'), 41), (('sorri', 'ill'), 39), (('r', 'u'), 37), (('u', 'r'), 37), (('dont', 'know'), 33), (('u', 'get'), 33), (('good', 'morn'), 31)]\n",
      "\n",
      "Top 10 3-grams: [(('ill', 'call', 'later'), 42), (('sorri', 'ill', 'call'), 38), (('im', 'gon', 'na'), 20), (('happi', 'new', 'year'), 19), (('pl', 'send', 'messag'), 13), (('cant', 'pick', 'phone'), 12), (('pick', 'phone', 'right'), 12), (('phone', 'right', 'pl'), 12), (('right', 'pl', 'send'), 12), (('hi', 'hi', 'hi'), 11)]\n",
      "\n",
      "Top 10 4-grams: [(('sorri', 'ill', 'call', 'later'), 38), (('cant', 'pick', 'phone', 'right'), 12), (('pick', 'phone', 'right', 'pl'), 12), (('phone', 'right', 'pl', 'send'), 12), (('right', 'pl', 'send', 'messag'), 12), (('ill', 'call', 'later', 'meet'), 6), (('pl', 'convey', 'birthday', 'wish'), 6), (('hi', 'hi', 'hi', 'hi'), 6), (('x', 'x', 'x', 'x'), 6), (('set', 'callertun', 'caller', 'press'), 5)]\n",
      "\n",
      "Top 10 5-grams: [(('cant', 'pick', 'phone', 'right', 'pl'), 12), (('pick', 'phone', 'right', 'pl', 'send'), 12), (('phone', 'right', 'pl', 'send', 'messag'), 12), (('sorri', 'ill', 'call', 'later', 'meet'), 6), (('set', 'callertun', 'caller', 'press', 'copi'), 5), (('callertun', 'caller', 'press', 'copi', 'friend'), 5), (('caller', 'press', 'copi', 'friend', 'callertun'), 5), (('enter', 'cabin', 'pa', 'say', 'happi'), 5), (('cabin', 'pa', 'say', 'happi', 'bday'), 5), (('pa', 'say', 'happi', 'bday', 'bo'), 5)]\n"
     ]
    }
   ],
   "source": [
    "#display the 10 most common n-grams for each level from 1 to 5\n",
    "for i in range(1, 6):\n",
    "    topham_ngrams = ham_ngram_count[i].most_common(10)\n",
    "    print(f\"\\nTop 10 {i}-grams:\", topham_ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "\n",
    "1. Analysis of Unigrams:\n",
    "    We can see that the top 10 most common unigrams are all related to calls and texts in both spam and ham messages but spam messages also have claim in the most common word list\n",
    "\n",
    "2. Analysis of Bigrams:\n",
    "    We can see that the top 10 most common bigrams are all still related to communication and/or delay in communication with spam messages still having claiming prizes as one of the most common elements.\n",
    "3. Analysis of Trigrams:\n",
    "    In trigrams we can see the difference between ham and spam becoming clearer. In spam messages, we can now clearly see that spam messages are more oriented towards claiming prizes, guarantees and calls. Meanwhile in ham messages there is a clear abundance of messages related to delayed communication.\n",
    "4. Analysis beyond Trigrams:\n",
    "    Beyond trigrams, the themes remain basically the same for both ham and spam messages with the exception that there is an inclusion of birthday congratulations in ham."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1 (Urdu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Reading/Data Frame Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>News Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>URL</th>\n",
       "      <th>Source</th>\n",
       "      <th>News length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>عالمی بینک عسکریت پسندی سے متاثرہ خاندانوں کی ...</td>\n",
       "      <td>اسلام باد عالمی بینک خیبرپختونخوا کے قبائلی اض...</td>\n",
       "      <td>Business &amp; Economics</td>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148499/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>مالی سال 2020 ریٹرن فائل کرنے والوں کی تعداد م...</td>\n",
       "      <td>اسلام باد فیڈرل بورڈ ریونیو ایف بی نے دسمبر کی...</td>\n",
       "      <td>Business &amp; Economics</td>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148498/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>جاپان کو سندھ کے خصوصی اقتصادی زون میں سرمایہ ...</td>\n",
       "      <td>اسلام باد بورڈ انویسٹمنٹ بی او ئی کے چیئرمین ع...</td>\n",
       "      <td>Business &amp; Economics</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148433/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>برامدات 767 فیصد بڑھ کر ارب 16 کروڑ ڈالر سے زائد</td>\n",
       "      <td>اسلام اباد پاکستان میں ماہ نومبر میں مسلسل تیس...</td>\n",
       "      <td>Business &amp; Economics</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148430/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>کے الیکٹرک کو اضافی بجلی گیس کی فراہمی کے قانو...</td>\n",
       "      <td>اسلام باد نیشنل ٹرانسمیشن اینڈ ڈسپیچ کمپنی این...</td>\n",
       "      <td>Business &amp; Economics</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148421/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0  عالمی بینک عسکریت پسندی سے متاثرہ خاندانوں کی ...   \n",
       "1  مالی سال 2020 ریٹرن فائل کرنے والوں کی تعداد م...   \n",
       "2  جاپان کو سندھ کے خصوصی اقتصادی زون میں سرمایہ ...   \n",
       "3   برامدات 767 فیصد بڑھ کر ارب 16 کروڑ ڈالر سے زائد   \n",
       "4  کے الیکٹرک کو اضافی بجلی گیس کی فراہمی کے قانو...   \n",
       "\n",
       "                                           News Text              Category  \\\n",
       "0  اسلام باد عالمی بینک خیبرپختونخوا کے قبائلی اض...  Business & Economics   \n",
       "1  اسلام باد فیڈرل بورڈ ریونیو ایف بی نے دسمبر کی...  Business & Economics   \n",
       "2  اسلام باد بورڈ انویسٹمنٹ بی او ئی کے چیئرمین ع...  Business & Economics   \n",
       "3  اسلام اباد پاکستان میں ماہ نومبر میں مسلسل تیس...  Business & Economics   \n",
       "4  اسلام باد نیشنل ٹرانسمیشن اینڈ ڈسپیچ کمپنی این...  Business & Economics   \n",
       "\n",
       "         Date                                    URL     Source News length  \n",
       "0  2020-12-06  https://www.dawnnews.tv/news/1148499/  Dawn News        1854  \n",
       "1  2020-12-06  https://www.dawnnews.tv/news/1148498/  Dawn News        2016  \n",
       "2  2020-12-05  https://www.dawnnews.tv/news/1148433/  Dawn News        2195  \n",
       "3  2020-12-05  https://www.dawnnews.tv/news/1148430/  Dawn News        2349  \n",
       "4  2020-12-05  https://www.dawnnews.tv/news/1148421/  Dawn News        2655  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"urdu.txt\", encoding=\"UTF-8-SIG\", errors='ignore') as file:\n",
    "    lines = file.readlines()\n",
    "    \n",
    "header = lines[0].strip().split(',')\n",
    "lines = [line.strip() for line in lines[1:]]  # Skip the first line for data\n",
    "[line.split(',') for line in lines]\n",
    "urdu = pd.DataFrame([line.split(',') for line in lines], columns=['Index',\n",
    " 'Headline',\n",
    " 'News Text',\n",
    " 'Category',\n",
    " 'Date',\n",
    " 'URL',\n",
    " 'Source',\n",
    " 'News length',\n",
    " 'x'])\n",
    "urdu = urdu.drop(columns=['Index', 'x'])\n",
    "urdu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>News Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>URL</th>\n",
       "      <th>Source</th>\n",
       "      <th>News length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>عالمی بینک عسکریت پسندی سے متاثرہ خاندانوں کی ...</td>\n",
       "      <td>اسلام باد عالمی بینک خیبرپختونخوا کے قبائلی اض...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148499/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>مالی سال  ریٹرن فائل کرنے والوں کی تعداد میں  ...</td>\n",
       "      <td>اسلام باد فیڈرل بورڈ ریونیو ایف بی نے دسمبر کی...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148498/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>جاپان کو سندھ کے خصوصی اقتصادی زون میں سرمایہ ...</td>\n",
       "      <td>اسلام باد بورڈ انویسٹمنٹ بی او ئی کے چیئرمین ع...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148433/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>برامدات  فیصد بڑھ کر ارب  کروڑ ڈالر سے زائد</td>\n",
       "      <td>اسلام اباد پاکستان میں ماہ نومبر میں مسلسل تیس...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148430/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>کے الیکٹرک کو اضافی بجلی گیس کی فراہمی کے قانو...</td>\n",
       "      <td>اسلام باد نیشنل ٹرانسمیشن اینڈ ڈسپیچ کمپنی این...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148421/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0  عالمی بینک عسکریت پسندی سے متاثرہ خاندانوں کی ...   \n",
       "1  مالی سال  ریٹرن فائل کرنے والوں کی تعداد میں  ...   \n",
       "2  جاپان کو سندھ کے خصوصی اقتصادی زون میں سرمایہ ...   \n",
       "3        برامدات  فیصد بڑھ کر ارب  کروڑ ڈالر سے زائد   \n",
       "4  کے الیکٹرک کو اضافی بجلی گیس کی فراہمی کے قانو...   \n",
       "\n",
       "                                           News Text             Category  \\\n",
       "0  اسلام باد عالمی بینک خیبرپختونخوا کے قبائلی اض...  business  economics   \n",
       "1  اسلام باد فیڈرل بورڈ ریونیو ایف بی نے دسمبر کی...  business  economics   \n",
       "2  اسلام باد بورڈ انویسٹمنٹ بی او ئی کے چیئرمین ع...  business  economics   \n",
       "3  اسلام اباد پاکستان میں ماہ نومبر میں مسلسل تیس...  business  economics   \n",
       "4  اسلام باد نیشنل ٹرانسمیشن اینڈ ڈسپیچ کمپنی این...  business  economics   \n",
       "\n",
       "         Date                                    URL     Source News length  \n",
       "0  2020-12-06  https://www.dawnnews.tv/news/1148499/  Dawn News        1854  \n",
       "1  2020-12-06  https://www.dawnnews.tv/news/1148498/  Dawn News        2016  \n",
       "2  2020-12-05  https://www.dawnnews.tv/news/1148433/  Dawn News        2195  \n",
       "3  2020-12-05  https://www.dawnnews.tv/news/1148430/  Dawn News        2349  \n",
       "4  2020-12-05  https://www.dawnnews.tv/news/1148421/  Dawn News        2655  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urdu['Headline'] = urdu['Headline'].str.replace(r'[^\\w\\s]', '', regex=True) #remove punctuation\n",
    "urdu['Headline'] = urdu['Headline'].str.replace(r'\\d+', '', regex=True) #remove numbers\n",
    "urdu['News Text'] = urdu['News Text'].str.replace(r'[^\\w\\s]', '', regex=True) #remove punctuation\n",
    "urdu['News Text'] = urdu['News Text'].str.replace(r'\\d+', '', regex=True) #remove numbers\n",
    "urdu['Category'] = urdu['Category'].str.replace(r'[^\\w\\s]', '', regex=True) #remove punctuation\n",
    "urdu['Category'] = urdu['Category'].str.lower() #convert to lowercase\n",
    "urdu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>News Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>URL</th>\n",
       "      <th>Source</th>\n",
       "      <th>News length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>عالمی بینک عسکریت پسندی سے متاثرہ خاندانوں معا...</td>\n",
       "      <td>اسلام باد عالمی بینک خیبرپختونخوا قبائلی اضلاع...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148499/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>مالی سال ریٹرن فائل کرنے والوں تعداد میں فیصد کمی</td>\n",
       "      <td>اسلام باد فیڈرل بورڈ ریونیو ایف بی نے دسمبر خر...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148498/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>جاپان کو سندھ خصوصی اقتصادی زون میں سرمایہ کار...</td>\n",
       "      <td>اسلام باد بورڈ انویسٹمنٹ بی او ئی چیئرمین عاطف...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148433/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>برامدات فیصد بڑھ کر ارب کروڑ ڈالر سے زائد</td>\n",
       "      <td>اسلام اباد پاکستان میں ماہ نومبر میں مسلسل تیس...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148430/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الیکٹرک کو اضافی بجلی گیس فراہمی قانونی تقاضے ...</td>\n",
       "      <td>اسلام باد نیشنل ٹرانسمیشن اینڈ ڈسپیچ کمپنی این...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148421/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0  عالمی بینک عسکریت پسندی سے متاثرہ خاندانوں معا...   \n",
       "1  مالی سال ریٹرن فائل کرنے والوں تعداد میں فیصد کمی   \n",
       "2  جاپان کو سندھ خصوصی اقتصادی زون میں سرمایہ کار...   \n",
       "3          برامدات فیصد بڑھ کر ارب کروڑ ڈالر سے زائد   \n",
       "4  الیکٹرک کو اضافی بجلی گیس فراہمی قانونی تقاضے ...   \n",
       "\n",
       "                                           News Text             Category  \\\n",
       "0  اسلام باد عالمی بینک خیبرپختونخوا قبائلی اضلاع...  business  economics   \n",
       "1  اسلام باد فیڈرل بورڈ ریونیو ایف بی نے دسمبر خر...  business  economics   \n",
       "2  اسلام باد بورڈ انویسٹمنٹ بی او ئی چیئرمین عاطف...  business  economics   \n",
       "3  اسلام اباد پاکستان میں ماہ نومبر میں مسلسل تیس...  business  economics   \n",
       "4  اسلام باد نیشنل ٹرانسمیشن اینڈ ڈسپیچ کمپنی این...  business  economics   \n",
       "\n",
       "         Date                                    URL     Source News length  \n",
       "0  2020-12-06  https://www.dawnnews.tv/news/1148499/  Dawn News        1854  \n",
       "1  2020-12-06  https://www.dawnnews.tv/news/1148498/  Dawn News        2016  \n",
       "2  2020-12-05  https://www.dawnnews.tv/news/1148433/  Dawn News        2195  \n",
       "3  2020-12-05  https://www.dawnnews.tv/news/1148430/  Dawn News        2349  \n",
       "4  2020-12-05  https://www.dawnnews.tv/news/1148421/  Dawn News        2655  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reduce dataset to reduce computation time\n",
    "urdu = urdu.head(5)\n",
    "\n",
    "\n",
    "#read file named stopwords-ur.txt and use the words in it as stopwords\n",
    "with open('stopwords-ur.txt', 'r', encoding='utf-8') as file:\n",
    "    stopwords_ur = file.read().splitlines()\n",
    "    \n",
    "urdu['Headline'] = urdu['Headline'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords_ur]))\n",
    "urdu['News Text'] = urdu['News Text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords_ur]))\n",
    "urdu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>News Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>URL</th>\n",
       "      <th>Source</th>\n",
       "      <th>News length</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>عالمی بینک عسکریت پسندی سے متاثرہ خاندانوں معا...</td>\n",
       "      <td>اسلام باد عالمی بینک خیبرپختونخوا قبائلی اضلاع...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148499/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>1854</td>\n",
       "      <td>[عالمی, بینک, عسکریت, پسندی, سے, متاثرہ, خاندا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>مالی سال ریٹرن فائل کرنے والوں تعداد میں فیصد کمی</td>\n",
       "      <td>اسلام باد فیڈرل بورڈ ریونیو ایف بی نے دسمبر خر...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148498/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2016</td>\n",
       "      <td>[مالی, سال, ریٹرن, فائل, کرنے, والوں, تعداد, م...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>جاپان کو سندھ خصوصی اقتصادی زون میں سرمایہ کار...</td>\n",
       "      <td>اسلام باد بورڈ انویسٹمنٹ بی او ئی چیئرمین عاطف...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148433/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2195</td>\n",
       "      <td>[جاپان, کو, سندھ, خصوصی, اقتصادی, زون, میں, سر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>برامدات فیصد بڑھ کر ارب کروڑ ڈالر سے زائد</td>\n",
       "      <td>اسلام اباد پاکستان میں ماہ نومبر میں مسلسل تیس...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148430/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2349</td>\n",
       "      <td>[برامدات, فیصد, بڑھ, کر, ارب, کروڑ, ڈالر, سے, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الیکٹرک کو اضافی بجلی گیس فراہمی قانونی تقاضے ...</td>\n",
       "      <td>اسلام باد نیشنل ٹرانسمیشن اینڈ ڈسپیچ کمپنی این...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148421/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2655</td>\n",
       "      <td>[الیکٹرک, کو, اضافی, بجلی, گیس, فراہمی, قانونی...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0  عالمی بینک عسکریت پسندی سے متاثرہ خاندانوں معا...   \n",
       "1  مالی سال ریٹرن فائل کرنے والوں تعداد میں فیصد کمی   \n",
       "2  جاپان کو سندھ خصوصی اقتصادی زون میں سرمایہ کار...   \n",
       "3          برامدات فیصد بڑھ کر ارب کروڑ ڈالر سے زائد   \n",
       "4  الیکٹرک کو اضافی بجلی گیس فراہمی قانونی تقاضے ...   \n",
       "\n",
       "                                           News Text             Category  \\\n",
       "0  اسلام باد عالمی بینک خیبرپختونخوا قبائلی اضلاع...  business  economics   \n",
       "1  اسلام باد فیڈرل بورڈ ریونیو ایف بی نے دسمبر خر...  business  economics   \n",
       "2  اسلام باد بورڈ انویسٹمنٹ بی او ئی چیئرمین عاطف...  business  economics   \n",
       "3  اسلام اباد پاکستان میں ماہ نومبر میں مسلسل تیس...  business  economics   \n",
       "4  اسلام باد نیشنل ٹرانسمیشن اینڈ ڈسپیچ کمپنی این...  business  economics   \n",
       "\n",
       "         Date                                    URL     Source News length  \\\n",
       "0  2020-12-06  https://www.dawnnews.tv/news/1148499/  Dawn News        1854   \n",
       "1  2020-12-06  https://www.dawnnews.tv/news/1148498/  Dawn News        2016   \n",
       "2  2020-12-05  https://www.dawnnews.tv/news/1148433/  Dawn News        2195   \n",
       "3  2020-12-05  https://www.dawnnews.tv/news/1148430/  Dawn News        2349   \n",
       "4  2020-12-05  https://www.dawnnews.tv/news/1148421/  Dawn News        2655   \n",
       "\n",
       "                                              tokens  \n",
       "0  [عالمی, بینک, عسکریت, پسندی, سے, متاثرہ, خاندا...  \n",
       "1  [مالی, سال, ریٹرن, فائل, کرنے, والوں, تعداد, م...  \n",
       "2  [جاپان, کو, سندھ, خصوصی, اقتصادی, زون, میں, سر...  \n",
       "3  [برامدات, فیصد, بڑھ, کر, ارب, کروڑ, ڈالر, سے, ...  \n",
       "4  [الیکٹرک, کو, اضافی, بجلی, گیس, فراہمی, قانونی...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urdu['tokens'] = urdu['Headline'].apply(word_tokenize)\n",
    "urdu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>News Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>URL</th>\n",
       "      <th>Source</th>\n",
       "      <th>News length</th>\n",
       "      <th>tokens</th>\n",
       "      <th>processed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>عالمی بینک عسکریت پسندی سے متاثرہ خاندانوں معا...</td>\n",
       "      <td>اسلام باد عالمی بینک خیبرپختونخوا قبائلی اضلاع...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148499/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>1854</td>\n",
       "      <td>[عالمی, بینک, عسکریت, پسندی, سے, متاثرہ, خاندا...</td>\n",
       "      <td>[عالمی, بینک, عسکریت, پسندی, سے, متاثرہ, خاندا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>مالی سال ریٹرن فائل کرنے والوں تعداد میں فیصد کمی</td>\n",
       "      <td>اسلام باد فیڈرل بورڈ ریونیو ایف بی نے دسمبر خر...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148498/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2016</td>\n",
       "      <td>[مالی, سال, ریٹرن, فائل, کرنے, والوں, تعداد, م...</td>\n",
       "      <td>[مالی, سال, ریٹرن, فائل, کرنے, والوں, تعداد, م...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>جاپان کو سندھ خصوصی اقتصادی زون میں سرمایہ کار...</td>\n",
       "      <td>اسلام باد بورڈ انویسٹمنٹ بی او ئی چیئرمین عاطف...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148433/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2195</td>\n",
       "      <td>[جاپان, کو, سندھ, خصوصی, اقتصادی, زون, میں, سر...</td>\n",
       "      <td>[جاپان, کو, سندھ, خصوصی, اقتصادی, زون, میں, سر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>برامدات فیصد بڑھ کر ارب کروڑ ڈالر سے زائد</td>\n",
       "      <td>اسلام اباد پاکستان میں ماہ نومبر میں مسلسل تیس...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148430/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2349</td>\n",
       "      <td>[برامدات, فیصد, بڑھ, کر, ارب, کروڑ, ڈالر, سے, ...</td>\n",
       "      <td>[برامدات, فیصد, بڑھ, کر, ارب, کروڑ, ڈالر, سے, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الیکٹرک کو اضافی بجلی گیس فراہمی قانونی تقاضے ...</td>\n",
       "      <td>اسلام باد نیشنل ٹرانسمیشن اینڈ ڈسپیچ کمپنی این...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148421/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2655</td>\n",
       "      <td>[الیکٹرک, کو, اضافی, بجلی, گیس, فراہمی, قانونی...</td>\n",
       "      <td>[الیکٹرک, کو, اضافی, بجلی, گیس, فراہمی, قانونی...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0  عالمی بینک عسکریت پسندی سے متاثرہ خاندانوں معا...   \n",
       "1  مالی سال ریٹرن فائل کرنے والوں تعداد میں فیصد کمی   \n",
       "2  جاپان کو سندھ خصوصی اقتصادی زون میں سرمایہ کار...   \n",
       "3          برامدات فیصد بڑھ کر ارب کروڑ ڈالر سے زائد   \n",
       "4  الیکٹرک کو اضافی بجلی گیس فراہمی قانونی تقاضے ...   \n",
       "\n",
       "                                           News Text             Category  \\\n",
       "0  اسلام باد عالمی بینک خیبرپختونخوا قبائلی اضلاع...  business  economics   \n",
       "1  اسلام باد فیڈرل بورڈ ریونیو ایف بی نے دسمبر خر...  business  economics   \n",
       "2  اسلام باد بورڈ انویسٹمنٹ بی او ئی چیئرمین عاطف...  business  economics   \n",
       "3  اسلام اباد پاکستان میں ماہ نومبر میں مسلسل تیس...  business  economics   \n",
       "4  اسلام باد نیشنل ٹرانسمیشن اینڈ ڈسپیچ کمپنی این...  business  economics   \n",
       "\n",
       "         Date                                    URL     Source News length  \\\n",
       "0  2020-12-06  https://www.dawnnews.tv/news/1148499/  Dawn News        1854   \n",
       "1  2020-12-06  https://www.dawnnews.tv/news/1148498/  Dawn News        2016   \n",
       "2  2020-12-05  https://www.dawnnews.tv/news/1148433/  Dawn News        2195   \n",
       "3  2020-12-05  https://www.dawnnews.tv/news/1148430/  Dawn News        2349   \n",
       "4  2020-12-05  https://www.dawnnews.tv/news/1148421/  Dawn News        2655   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [عالمی, بینک, عسکریت, پسندی, سے, متاثرہ, خاندا...   \n",
       "1  [مالی, سال, ریٹرن, فائل, کرنے, والوں, تعداد, م...   \n",
       "2  [جاپان, کو, سندھ, خصوصی, اقتصادی, زون, میں, سر...   \n",
       "3  [برامدات, فیصد, بڑھ, کر, ارب, کروڑ, ڈالر, سے, ...   \n",
       "4  [الیکٹرک, کو, اضافی, بجلی, گیس, فراہمی, قانونی...   \n",
       "\n",
       "                                    processed_tokens  \n",
       "0  [عالمی, بینک, عسکریت, پسندی, سے, متاثرہ, خاندا...  \n",
       "1  [مالی, سال, ریٹرن, فائل, کرنے, والوں, تعداد, م...  \n",
       "2  [جاپان, کو, سندھ, خصوصی, اقتصادی, زون, میں, سر...  \n",
       "3  [برامدات, فیصد, بڑھ, کر, ارب, کروڑ, ڈالر, سے, ...  \n",
       "4  [الیکٹرک, کو, اضافی, بجلی, گیس, فراہمی, قانونی...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lemmatize the tokens with POS tagging\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "#Apply Lemmatization and Stemming\n",
    "def process_tokens(tokens):\n",
    "    #POS Tagging\n",
    "    pos_tagged_tokens = pos_tag(tokens)  # Tag each token with its POS\n",
    "    \n",
    "    #Lemmatization with PartOfSpeech tagging\n",
    "    lemmatized_tokens = [\n",
    "        lemmatizer.lemmatize(token, get_wordnet_pos(pos)) for token, pos in pos_tagged_tokens\n",
    "    ]\n",
    "    \n",
    "    #Stemming\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in lemmatized_tokens]\n",
    "    \n",
    "    return stemmed_tokens\n",
    "\n",
    "urdu['processed_tokens'] = urdu['tokens'].apply(process_tokens)\n",
    "urdu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N-Gram Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>News Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>URL</th>\n",
       "      <th>Source</th>\n",
       "      <th>News length</th>\n",
       "      <th>tokens</th>\n",
       "      <th>processed_tokens</th>\n",
       "      <th>ngrams_1</th>\n",
       "      <th>ngrams_2</th>\n",
       "      <th>ngrams_3</th>\n",
       "      <th>ngrams_4</th>\n",
       "      <th>ngrams_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>عالمی بینک عسکریت پسندی سے متاثرہ خاندانوں معا...</td>\n",
       "      <td>اسلام باد عالمی بینک خیبرپختونخوا قبائلی اضلاع...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148499/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>1854</td>\n",
       "      <td>[عالمی, بینک, عسکریت, پسندی, سے, متاثرہ, خاندا...</td>\n",
       "      <td>[عالمی, بینک, عسکریت, پسندی, سے, متاثرہ, خاندا...</td>\n",
       "      <td>[(عالمی,), (بینک,), (عسکریت,), (پسندی,), (سے,)...</td>\n",
       "      <td>[(عالمی, بینک), (بینک, عسکریت), (عسکریت, پسندی...</td>\n",
       "      <td>[(عالمی, بینک, عسکریت), (بینک, عسکریت, پسندی),...</td>\n",
       "      <td>[(عالمی, بینک, عسکریت, پسندی), (بینک, عسکریت, ...</td>\n",
       "      <td>[(عالمی, بینک, عسکریت, پسندی, سے), (بینک, عسکر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>مالی سال ریٹرن فائل کرنے والوں تعداد میں فیصد کمی</td>\n",
       "      <td>اسلام باد فیڈرل بورڈ ریونیو ایف بی نے دسمبر خر...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148498/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2016</td>\n",
       "      <td>[مالی, سال, ریٹرن, فائل, کرنے, والوں, تعداد, م...</td>\n",
       "      <td>[مالی, سال, ریٹرن, فائل, کرنے, والوں, تعداد, م...</td>\n",
       "      <td>[(مالی,), (سال,), (ریٹرن,), (فائل,), (کرنے,), ...</td>\n",
       "      <td>[(مالی, سال), (سال, ریٹرن), (ریٹرن, فائل), (فا...</td>\n",
       "      <td>[(مالی, سال, ریٹرن), (سال, ریٹرن, فائل), (ریٹر...</td>\n",
       "      <td>[(مالی, سال, ریٹرن, فائل), (سال, ریٹرن, فائل, ...</td>\n",
       "      <td>[(مالی, سال, ریٹرن, فائل, کرنے), (سال, ریٹرن, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>جاپان کو سندھ خصوصی اقتصادی زون میں سرمایہ کار...</td>\n",
       "      <td>اسلام باد بورڈ انویسٹمنٹ بی او ئی چیئرمین عاطف...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148433/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2195</td>\n",
       "      <td>[جاپان, کو, سندھ, خصوصی, اقتصادی, زون, میں, سر...</td>\n",
       "      <td>[جاپان, کو, سندھ, خصوصی, اقتصادی, زون, میں, سر...</td>\n",
       "      <td>[(جاپان,), (کو,), (سندھ,), (خصوصی,), (اقتصادی,...</td>\n",
       "      <td>[(جاپان, کو), (کو, سندھ), (سندھ, خصوصی), (خصوص...</td>\n",
       "      <td>[(جاپان, کو, سندھ), (کو, سندھ, خصوصی), (سندھ, ...</td>\n",
       "      <td>[(جاپان, کو, سندھ, خصوصی), (کو, سندھ, خصوصی, ا...</td>\n",
       "      <td>[(جاپان, کو, سندھ, خصوصی, اقتصادی), (کو, سندھ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>برامدات فیصد بڑھ کر ارب کروڑ ڈالر سے زائد</td>\n",
       "      <td>اسلام اباد پاکستان میں ماہ نومبر میں مسلسل تیس...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148430/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2349</td>\n",
       "      <td>[برامدات, فیصد, بڑھ, کر, ارب, کروڑ, ڈالر, سے, ...</td>\n",
       "      <td>[برامدات, فیصد, بڑھ, کر, ارب, کروڑ, ڈالر, سے, ...</td>\n",
       "      <td>[(برامدات,), (فیصد,), (بڑھ,), (کر,), (ارب,), (...</td>\n",
       "      <td>[(برامدات, فیصد), (فیصد, بڑھ), (بڑھ, کر), (کر,...</td>\n",
       "      <td>[(برامدات, فیصد, بڑھ), (فیصد, بڑھ, کر), (بڑھ, ...</td>\n",
       "      <td>[(برامدات, فیصد, بڑھ, کر), (فیصد, بڑھ, کر, ارب...</td>\n",
       "      <td>[(برامدات, فیصد, بڑھ, کر, ارب), (فیصد, بڑھ, کر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الیکٹرک کو اضافی بجلی گیس فراہمی قانونی تقاضے ...</td>\n",
       "      <td>اسلام باد نیشنل ٹرانسمیشن اینڈ ڈسپیچ کمپنی این...</td>\n",
       "      <td>business  economics</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>https://www.dawnnews.tv/news/1148421/</td>\n",
       "      <td>Dawn News</td>\n",
       "      <td>2655</td>\n",
       "      <td>[الیکٹرک, کو, اضافی, بجلی, گیس, فراہمی, قانونی...</td>\n",
       "      <td>[الیکٹرک, کو, اضافی, بجلی, گیس, فراہمی, قانونی...</td>\n",
       "      <td>[(الیکٹرک,), (کو,), (اضافی,), (بجلی,), (گیس,),...</td>\n",
       "      <td>[(الیکٹرک, کو), (کو, اضافی), (اضافی, بجلی), (ب...</td>\n",
       "      <td>[(الیکٹرک, کو, اضافی), (کو, اضافی, بجلی), (اضا...</td>\n",
       "      <td>[(الیکٹرک, کو, اضافی, بجلی), (کو, اضافی, بجلی,...</td>\n",
       "      <td>[(الیکٹرک, کو, اضافی, بجلی, گیس), (کو, اضافی, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0  عالمی بینک عسکریت پسندی سے متاثرہ خاندانوں معا...   \n",
       "1  مالی سال ریٹرن فائل کرنے والوں تعداد میں فیصد کمی   \n",
       "2  جاپان کو سندھ خصوصی اقتصادی زون میں سرمایہ کار...   \n",
       "3          برامدات فیصد بڑھ کر ارب کروڑ ڈالر سے زائد   \n",
       "4  الیکٹرک کو اضافی بجلی گیس فراہمی قانونی تقاضے ...   \n",
       "\n",
       "                                           News Text             Category  \\\n",
       "0  اسلام باد عالمی بینک خیبرپختونخوا قبائلی اضلاع...  business  economics   \n",
       "1  اسلام باد فیڈرل بورڈ ریونیو ایف بی نے دسمبر خر...  business  economics   \n",
       "2  اسلام باد بورڈ انویسٹمنٹ بی او ئی چیئرمین عاطف...  business  economics   \n",
       "3  اسلام اباد پاکستان میں ماہ نومبر میں مسلسل تیس...  business  economics   \n",
       "4  اسلام باد نیشنل ٹرانسمیشن اینڈ ڈسپیچ کمپنی این...  business  economics   \n",
       "\n",
       "         Date                                    URL     Source News length  \\\n",
       "0  2020-12-06  https://www.dawnnews.tv/news/1148499/  Dawn News        1854   \n",
       "1  2020-12-06  https://www.dawnnews.tv/news/1148498/  Dawn News        2016   \n",
       "2  2020-12-05  https://www.dawnnews.tv/news/1148433/  Dawn News        2195   \n",
       "3  2020-12-05  https://www.dawnnews.tv/news/1148430/  Dawn News        2349   \n",
       "4  2020-12-05  https://www.dawnnews.tv/news/1148421/  Dawn News        2655   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [عالمی, بینک, عسکریت, پسندی, سے, متاثرہ, خاندا...   \n",
       "1  [مالی, سال, ریٹرن, فائل, کرنے, والوں, تعداد, م...   \n",
       "2  [جاپان, کو, سندھ, خصوصی, اقتصادی, زون, میں, سر...   \n",
       "3  [برامدات, فیصد, بڑھ, کر, ارب, کروڑ, ڈالر, سے, ...   \n",
       "4  [الیکٹرک, کو, اضافی, بجلی, گیس, فراہمی, قانونی...   \n",
       "\n",
       "                                    processed_tokens  \\\n",
       "0  [عالمی, بینک, عسکریت, پسندی, سے, متاثرہ, خاندا...   \n",
       "1  [مالی, سال, ریٹرن, فائل, کرنے, والوں, تعداد, م...   \n",
       "2  [جاپان, کو, سندھ, خصوصی, اقتصادی, زون, میں, سر...   \n",
       "3  [برامدات, فیصد, بڑھ, کر, ارب, کروڑ, ڈالر, سے, ...   \n",
       "4  [الیکٹرک, کو, اضافی, بجلی, گیس, فراہمی, قانونی...   \n",
       "\n",
       "                                            ngrams_1  \\\n",
       "0  [(عالمی,), (بینک,), (عسکریت,), (پسندی,), (سے,)...   \n",
       "1  [(مالی,), (سال,), (ریٹرن,), (فائل,), (کرنے,), ...   \n",
       "2  [(جاپان,), (کو,), (سندھ,), (خصوصی,), (اقتصادی,...   \n",
       "3  [(برامدات,), (فیصد,), (بڑھ,), (کر,), (ارب,), (...   \n",
       "4  [(الیکٹرک,), (کو,), (اضافی,), (بجلی,), (گیس,),...   \n",
       "\n",
       "                                            ngrams_2  \\\n",
       "0  [(عالمی, بینک), (بینک, عسکریت), (عسکریت, پسندی...   \n",
       "1  [(مالی, سال), (سال, ریٹرن), (ریٹرن, فائل), (فا...   \n",
       "2  [(جاپان, کو), (کو, سندھ), (سندھ, خصوصی), (خصوص...   \n",
       "3  [(برامدات, فیصد), (فیصد, بڑھ), (بڑھ, کر), (کر,...   \n",
       "4  [(الیکٹرک, کو), (کو, اضافی), (اضافی, بجلی), (ب...   \n",
       "\n",
       "                                            ngrams_3  \\\n",
       "0  [(عالمی, بینک, عسکریت), (بینک, عسکریت, پسندی),...   \n",
       "1  [(مالی, سال, ریٹرن), (سال, ریٹرن, فائل), (ریٹر...   \n",
       "2  [(جاپان, کو, سندھ), (کو, سندھ, خصوصی), (سندھ, ...   \n",
       "3  [(برامدات, فیصد, بڑھ), (فیصد, بڑھ, کر), (بڑھ, ...   \n",
       "4  [(الیکٹرک, کو, اضافی), (کو, اضافی, بجلی), (اضا...   \n",
       "\n",
       "                                            ngrams_4  \\\n",
       "0  [(عالمی, بینک, عسکریت, پسندی), (بینک, عسکریت, ...   \n",
       "1  [(مالی, سال, ریٹرن, فائل), (سال, ریٹرن, فائل, ...   \n",
       "2  [(جاپان, کو, سندھ, خصوصی), (کو, سندھ, خصوصی, ا...   \n",
       "3  [(برامدات, فیصد, بڑھ, کر), (فیصد, بڑھ, کر, ارب...   \n",
       "4  [(الیکٹرک, کو, اضافی, بجلی), (کو, اضافی, بجلی,...   \n",
       "\n",
       "                                            ngrams_5  \n",
       "0  [(عالمی, بینک, عسکریت, پسندی, سے), (بینک, عسکر...  \n",
       "1  [(مالی, سال, ریٹرن, فائل, کرنے), (سال, ریٹرن, ...  \n",
       "2  [(جاپان, کو, سندھ, خصوصی, اقتصادی), (کو, سندھ,...  \n",
       "3  [(برامدات, فیصد, بڑھ, کر, ارب), (فیصد, بڑھ, کر...  \n",
       "4  [(الیکٹرک, کو, اضافی, بجلی, گیس), (کو, اضافی, ...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    column_name = f'ngrams_{i}'\n",
    "    urdu[column_name] = urdu['processed_tokens'].apply(lambda x: ngram_generator(x, i))\n",
    "urdu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N-Gram Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 1-grams in Headlines: [(('سے',), 2), (('میں',), 2), (('فیصد',), 2), (('کو',), 2), (('عالمی',), 1)]\n",
      "\n",
      "Top 5 2-grams in Headlines: [(('عالمی', 'بینک'), 1), (('بینک', 'عسکریت'), 1), (('عسکریت', 'پسندی'), 1), (('پسندی', 'سے'), 1), (('سے', 'متاثرہ'), 1)]\n",
      "\n",
      "Top 5 3-grams in Headlines: [(('عالمی', 'بینک', 'عسکریت'), 1), (('بینک', 'عسکریت', 'پسندی'), 1), (('عسکریت', 'پسندی', 'سے'), 1), (('پسندی', 'سے', 'متاثرہ'), 1), (('سے', 'متاثرہ', 'خاندانوں'), 1)]\n",
      "\n",
      "Top 5 4-grams in Headlines: [(('عالمی', 'بینک', 'عسکریت', 'پسندی'), 1), (('بینک', 'عسکریت', 'پسندی', 'سے'), 1), (('عسکریت', 'پسندی', 'سے', 'متاثرہ'), 1), (('پسندی', 'سے', 'متاثرہ', 'خاندانوں'), 1), (('سے', 'متاثرہ', 'خاندانوں', 'معاونت'), 1)]\n",
      "\n",
      "Top 5 5-grams in Headlines: [(('عالمی', 'بینک', 'عسکریت', 'پسندی', 'سے'), 1), (('بینک', 'عسکریت', 'پسندی', 'سے', 'متاثرہ'), 1), (('عسکریت', 'پسندی', 'سے', 'متاثرہ', 'خاندانوں'), 1), (('پسندی', 'سے', 'متاثرہ', 'خاندانوں', 'معاونت'), 1), (('سے', 'متاثرہ', 'خاندانوں', 'معاونت', 'گا'), 1)]\n"
     ]
    }
   ],
   "source": [
    "urdu_ngram_count = {}\n",
    "for i in range(1, 6):\n",
    "    urdu_ngram_count[i] = Counter([ngram for ngrams_list in urdu[f'ngrams_{i}'] for ngram in ngrams_list])\n",
    "\n",
    "for i in range(1, 6):\n",
    "    print(f\"\\nTop 5 {i}-grams in Headlines:\", urdu_ngram_count[i].most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems with Urdu Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The biggest problem with the urdu dataset was that it wasn't being read properly on vscode even when using different types of encodings. In the end, I had to read the whole file line by line and manually create dataframe. After that it was easy. Stopwords were retrieved from github in a separate file as I could not get the nltk urdu stopwords to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read File and convert to Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>over hill over dale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thorough bush thorough brier over park over pale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thorough flood thorough fire i do wander every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>swifter than the moons sphere and i serve the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to dew her orbs upon the green the cowslips ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Line\n",
       "0                                over hill over dale\n",
       "1   thorough bush thorough brier over park over pale\n",
       "2  thorough flood thorough fire i do wander every...\n",
       "3  swifter than the moons sphere and i serve the ...\n",
       "4  to dew her orbs upon the green the cowslips ta..."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"robert.txt\", encoding=\"ISO-8859-1\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "#strip whitespace from each line and create a DataFrame\n",
    "lines = [line.strip() for line in lines]\n",
    "robert = pd.DataFrame(lines, columns=[\"Line\"])\n",
    "robert['Line'] = robert['Line'].str.lower() #convert to lowercase\n",
    "robert['Line'] = robert['Line'].str.strip() #strip whitespace\n",
    "robert['Line'] = robert['Line'].str.replace(r'[^\\w\\s]', '', regex=True) #remove punctuation\n",
    "robert['Line'] = robert['Line'].str.replace(r'\\d+', '', regex=True) #remove numbers\n",
    "robert.head()\n",
    "with open(\"shakespear.txt\", encoding=\"ISO-8859-1\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "#strip whitespace from each line and create a DataFrame\n",
    "lines = [line.strip() for line in lines]\n",
    "shakespeare = pd.DataFrame(lines, columns=[\"Line\"])\n",
    "shakespeare['Line'] = shakespeare['Line'].str.lower() #convert to lowercase\n",
    "shakespeare['Line'] = shakespeare['Line'].str.strip() #strip whitespace\n",
    "shakespeare['Line'] = shakespeare['Line'].str.replace(r'[^\\w\\s]', '', regex=True) #remove punctuation\n",
    "shakespeare['Line'] = shakespeare['Line'].str.replace(r'\\d+', '', regex=True) #remove numbers\n",
    "shakespeare.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>over hill over dale</td>\n",
       "      <td>[over, hill, over, dale]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thorough bush thorough brier over park over pale</td>\n",
       "      <td>[thorough, bush, thorough, brier, over, park, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thorough flood thorough fire i do wander every...</td>\n",
       "      <td>[thorough, flood, thorough, fire, i, do, wande...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>swifter than the moons sphere and i serve the ...</td>\n",
       "      <td>[swifter, than, the, moons, sphere, and, i, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to dew her orbs upon the green the cowslips ta...</td>\n",
       "      <td>[to, dew, her, orbs, upon, the, green, the, co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Line  \\\n",
       "0                                over hill over dale   \n",
       "1   thorough bush thorough brier over park over pale   \n",
       "2  thorough flood thorough fire i do wander every...   \n",
       "3  swifter than the moons sphere and i serve the ...   \n",
       "4  to dew her orbs upon the green the cowslips ta...   \n",
       "\n",
       "                                              tokens  \n",
       "0                           [over, hill, over, dale]  \n",
       "1  [thorough, bush, thorough, brier, over, park, ...  \n",
       "2  [thorough, flood, thorough, fire, i, do, wande...  \n",
       "3  [swifter, than, the, moons, sphere, and, i, se...  \n",
       "4  [to, dew, her, orbs, upon, the, green, the, co...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenization\n",
    "robert['tokens']=robert['Line'].apply(word_tokenize)\n",
    "shakespeare['tokens']=shakespeare['Line'].apply(word_tokenize)\n",
    "shakespeare.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unigrams of robert and shakespeare\n",
    "robert['unigrams'] = robert['tokens'].apply(lambda x: ngram_generator(x, 1))\n",
    "shakespeare['unigrams'] = shakespeare['tokens'].apply(lambda x: ngram_generator(x, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigrams of shakespeare and robert\n",
    "robert['bigrams'] = robert['tokens'].apply(lambda x: ngram_generator(x, 2))\n",
    "shakespeare['bigrams'] = shakespeare['tokens'].apply(lambda x: ngram_generator(x, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trigrams of shakespeare and robert\n",
    "robert['trigrams'] = robert['tokens'].apply(lambda x: ngram_generator(x, 3))\n",
    "shakespeare['trigrams'] = shakespeare['tokens'].apply(lambda x: ngram_generator(x, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>tokens</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a boundless moment</td>\n",
       "      <td>[a, boundless, moment]</td>\n",
       "      <td>[(a,), (boundless,), (moment,)]</td>\n",
       "      <td>[(a, boundless), (boundless, moment)]</td>\n",
       "      <td>[(a, boundless, moment)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he halted in the wind and  what was that</td>\n",
       "      <td>[he, halted, in, the, wind, and, what, was, that]</td>\n",
       "      <td>[(he,), (halted,), (in,), (the,), (wind,), (an...</td>\n",
       "      <td>[(he, halted), (halted, in), (in, the), (the, ...</td>\n",
       "      <td>[(he, halted, in), (halted, in, the), (in, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>far in the maples pale but not a ghost</td>\n",
       "      <td>[far, in, the, maples, pale, but, not, a, ghost]</td>\n",
       "      <td>[(far,), (in,), (the,), (maples,), (pale,), (b...</td>\n",
       "      <td>[(far, in), (in, the), (the, maples), (maples,...</td>\n",
       "      <td>[(far, in, the), (in, the, maples), (the, mapl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>he stood there bringing march against his thought</td>\n",
       "      <td>[he, stood, there, bringing, march, against, h...</td>\n",
       "      <td>[(he,), (stood,), (there,), (bringing,), (marc...</td>\n",
       "      <td>[(he, stood), (stood, there), (there, bringing...</td>\n",
       "      <td>[(he, stood, there), (stood, there, bringing),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and yet too ready to believe the most</td>\n",
       "      <td>[and, yet, too, ready, to, believe, the, most]</td>\n",
       "      <td>[(and,), (yet,), (too,), (ready,), (to,), (bel...</td>\n",
       "      <td>[(and, yet), (yet, too), (too, ready), (ready,...</td>\n",
       "      <td>[(and, yet, too), (yet, too, ready), (too, rea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Line  \\\n",
       "0                                 a boundless moment   \n",
       "1           he halted in the wind and  what was that   \n",
       "2             far in the maples pale but not a ghost   \n",
       "3  he stood there bringing march against his thought   \n",
       "4              and yet too ready to believe the most   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                             [a, boundless, moment]   \n",
       "1  [he, halted, in, the, wind, and, what, was, that]   \n",
       "2   [far, in, the, maples, pale, but, not, a, ghost]   \n",
       "3  [he, stood, there, bringing, march, against, h...   \n",
       "4     [and, yet, too, ready, to, believe, the, most]   \n",
       "\n",
       "                                            unigrams  \\\n",
       "0                    [(a,), (boundless,), (moment,)]   \n",
       "1  [(he,), (halted,), (in,), (the,), (wind,), (an...   \n",
       "2  [(far,), (in,), (the,), (maples,), (pale,), (b...   \n",
       "3  [(he,), (stood,), (there,), (bringing,), (marc...   \n",
       "4  [(and,), (yet,), (too,), (ready,), (to,), (bel...   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0              [(a, boundless), (boundless, moment)]   \n",
       "1  [(he, halted), (halted, in), (in, the), (the, ...   \n",
       "2  [(far, in), (in, the), (the, maples), (maples,...   \n",
       "3  [(he, stood), (stood, there), (there, bringing...   \n",
       "4  [(and, yet), (yet, too), (too, ready), (ready,...   \n",
       "\n",
       "                                            trigrams  \n",
       "0                           [(a, boundless, moment)]  \n",
       "1  [(he, halted, in), (halted, in, the), (in, the...  \n",
       "2  [(far, in, the), (in, the, maples), (the, mapl...  \n",
       "3  [(he, stood, there), (stood, there, bringing),...  \n",
       "4  [(and, yet, too), (yet, too, ready), (too, rea...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>tokens</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>over hill over dale</td>\n",
       "      <td>[over, hill, over, dale]</td>\n",
       "      <td>[(over,), (hill,), (over,), (dale,)]</td>\n",
       "      <td>[(over, hill), (hill, over), (over, dale)]</td>\n",
       "      <td>[(over, hill, over), (hill, over, dale)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thorough bush thorough brier over park over pale</td>\n",
       "      <td>[thorough, bush, thorough, brier, over, park, ...</td>\n",
       "      <td>[(thorough,), (bush,), (thorough,), (brier,), ...</td>\n",
       "      <td>[(thorough, bush), (bush, thorough), (thorough...</td>\n",
       "      <td>[(thorough, bush, thorough), (bush, thorough, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thorough flood thorough fire i do wander every...</td>\n",
       "      <td>[thorough, flood, thorough, fire, i, do, wande...</td>\n",
       "      <td>[(thorough,), (flood,), (thorough,), (fire,), ...</td>\n",
       "      <td>[(thorough, flood), (flood, thorough), (thorou...</td>\n",
       "      <td>[(thorough, flood, thorough), (flood, thorough...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>swifter than the moons sphere and i serve the ...</td>\n",
       "      <td>[swifter, than, the, moons, sphere, and, i, se...</td>\n",
       "      <td>[(swifter,), (than,), (the,), (moons,), (spher...</td>\n",
       "      <td>[(swifter, than), (than, the), (the, moons), (...</td>\n",
       "      <td>[(swifter, than, the), (than, the, moons), (th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to dew her orbs upon the green the cowslips ta...</td>\n",
       "      <td>[to, dew, her, orbs, upon, the, green, the, co...</td>\n",
       "      <td>[(to,), (dew,), (her,), (orbs,), (upon,), (the...</td>\n",
       "      <td>[(to, dew), (dew, her), (her, orbs), (orbs, up...</td>\n",
       "      <td>[(to, dew, her), (dew, her, orbs), (her, orbs,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Line  \\\n",
       "0                                over hill over dale   \n",
       "1   thorough bush thorough brier over park over pale   \n",
       "2  thorough flood thorough fire i do wander every...   \n",
       "3  swifter than the moons sphere and i serve the ...   \n",
       "4  to dew her orbs upon the green the cowslips ta...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                           [over, hill, over, dale]   \n",
       "1  [thorough, bush, thorough, brier, over, park, ...   \n",
       "2  [thorough, flood, thorough, fire, i, do, wande...   \n",
       "3  [swifter, than, the, moons, sphere, and, i, se...   \n",
       "4  [to, dew, her, orbs, upon, the, green, the, co...   \n",
       "\n",
       "                                            unigrams  \\\n",
       "0               [(over,), (hill,), (over,), (dale,)]   \n",
       "1  [(thorough,), (bush,), (thorough,), (brier,), ...   \n",
       "2  [(thorough,), (flood,), (thorough,), (fire,), ...   \n",
       "3  [(swifter,), (than,), (the,), (moons,), (spher...   \n",
       "4  [(to,), (dew,), (her,), (orbs,), (upon,), (the...   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0         [(over, hill), (hill, over), (over, dale)]   \n",
       "1  [(thorough, bush), (bush, thorough), (thorough...   \n",
       "2  [(thorough, flood), (flood, thorough), (thorou...   \n",
       "3  [(swifter, than), (than, the), (the, moons), (...   \n",
       "4  [(to, dew), (dew, her), (her, orbs), (orbs, up...   \n",
       "\n",
       "                                            trigrams  \n",
       "0           [(over, hill, over), (hill, over, dale)]  \n",
       "1  [(thorough, bush, thorough), (bush, thorough, ...  \n",
       "2  [(thorough, flood, thorough), (flood, thorough...  \n",
       "3  [(swifter, than, the), (than, the, moons), (th...  \n",
       "4  [(to, dew, her), (dew, her, orbs), (her, orbs,...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "robert_unigrams = [item for sublist in robert['unigrams'] for item in sublist]\n",
    "robert_bigrams = [item for sublist in robert['bigrams'] for item in sublist]\n",
    "robert_trigrams = [item for sublist in robert['trigrams'] for item in sublist]\n",
    "\n",
    "shakespeare_unigrams = [item for sublist in shakespeare['unigrams'] for item in sublist]\n",
    "shakespeare_bigrams = [item for sublist in shakespeare['bigrams'] for item in sublist]\n",
    "shakespeare_trigrams = [item for sublist in shakespeare['trigrams'] for item in sublist]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poem Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import ConditionalFreqDist\n",
    "\n",
    "#function to create Conditional Frequency Distribution (CFD) for a list of n-grams\n",
    "def create_cfd(ngrams_list):\n",
    "    return ConditionalFreqDist((ngram[:-1], ngram[-1]) for ngram in ngrams_list)\n",
    "\n",
    "\n",
    "#create CFD models for Robert Frost\n",
    "robert_unigram_cfd = create_cfd(robert_unigrams)\n",
    "robert_bigram_cfd = create_cfd(robert_bigrams)\n",
    "robert_trigram_cfd = create_cfd(robert_trigrams)\n",
    "\n",
    "#create CFD models for William Shakespeare\n",
    "shakespeare_unigram_cfd = create_cfd(shakespeare_unigrams)\n",
    "shakespeare_bigram_cfd = create_cfd(shakespeare_bigrams)\n",
    "shakespeare_trigram_cfd = create_cfd(shakespeare_trigrams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Start with a randomly selected word.\n",
    "2. Use the trigram model to predict the next word whenever possible.\n",
    "3. Fall back to the bigram and then the unigram model if the trigram prediction isn’t available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#function to generate a line based on n-gram models\n",
    "def generate_line(start_word, unigram_cfd, bigram_cfd, trigram_cfd, min_len=7, max_len=10):\n",
    "    line = [start_word]\n",
    "    \n",
    "    while len(line) < max_len:\n",
    "        #try trigram\n",
    "        if len(line) >= 2 and (line[-2], line[-1]) in trigram_cfd:\n",
    "            next_word = trigram_cfd[(line[-2], line[-1])].max()\n",
    "        #else bigram\n",
    "        elif len(line) >= 1 and (line[-1],) in bigram_cfd:\n",
    "            next_word = bigram_cfd[(line[-1],)].max()\n",
    "        #else unigram\n",
    "        else:\n",
    "            next_word = unigram_cfd[()].max()\n",
    "\n",
    "        line.append(next_word)\n",
    "\n",
    "        #end line randomly between min_len and max_len words\n",
    "        if len(line) >= min_len and random.random() > 0.7:\n",
    "            break\n",
    "    \n",
    "    return ' '.join(line)\n",
    "\n",
    "#function to generate a poem with multiple stanzas\n",
    "def generate_poem(vocab, unigram_cfd, bigram_cfd, trigram_cfd, stanzas=3, lines_per_stanza=4):\n",
    "    poem = []\n",
    "    for k in range(stanzas):\n",
    "        stanza = []\n",
    "        for k in range(lines_per_stanza):\n",
    "            start_word = random.choice(vocab)  # Randomly select starting word\n",
    "            line = generate_line(start_word, unigram_cfd, bigram_cfd, trigram_cfd)\n",
    "            stanza.append(line)\n",
    "        poem.append('\\n'.join(stanza) + '\\n')\n",
    "    return '\\n'.join(poem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robert Frost Style Poem:\n",
      "\n",
      "preprimitives of the sun shines now no warmer than the\n",
      "drew back in its body song and\n",
      "whiter and whiter and whiter and whiter and\n",
      "swarm still ran and scuttled just as\n",
      "\n",
      "speck that would have been a quarry\n",
      "boy bend them down to stay done hellforleather the worlds\n",
      "neighbors may not have risen that so keep the\n",
      "lie in stones and bushes unretrieved the worlds poetry archive\n",
      "\n",
      "concerns the worlds poetry archive the worlds poetry archive the\n",
      "swarm still ran and scuttled just as fast oh fast\n",
      "frame the worlds poetry archive the worlds poetry archive the\n",
      "hatchery near canada the worlds poetry archive the\n",
      "\n",
      "William Shakespeare Style Poem:\n",
      "\n",
      "seanymphs hourly ring his knell dingdong and in my verse\n",
      "hearing die to themselves sweet roses do\n",
      "endowed she gave the more which bounteous gift thou\n",
      "combat doubtful that love is not so\n",
      "\n",
      "moones sphere nbspnbspnbspand i serve the fairy queen nbspnbspnbspto\n",
      "darken the day or night and weep\n",
      "shrieking undistinguishd woe and moan th expense of many a\n",
      "breath their masked buds discloses but for his scythe\n",
      "\n",
      "darkening thy power to hurt and will do none that\n",
      "beds revenues of their faces others but\n",
      "fancies sent me of thee this i prognosticate and\n",
      "cautels all strange forms receives of burning blushes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#extract vocabulary for each poet\n",
    "robert_vocab = list(set([token for sublist in robert['tokens'] for token in sublist]))\n",
    "shakespeare_vocab = list(set([token for sublist in shakespeare['tokens'] for token in sublist]))\n",
    "\n",
    "#generate Robert Frost style poem\n",
    "robert_poem = generate_poem(robert_vocab, robert_unigram_cfd, robert_bigram_cfd, robert_trigram_cfd)\n",
    "print(\"Robert Frost Style Poem:\\n\")\n",
    "print(robert_poem)\n",
    "\n",
    "#generate William Shakespeare style poem\n",
    "shakespeare_poem = generate_poem(shakespeare_vocab, shakespeare_unigram_cfd, shakespeare_bigram_cfd, shakespeare_trigram_cfd)\n",
    "print(\"William Shakespeare Style Poem:\\n\")\n",
    "print(shakespeare_poem)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
